{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This porject aims to study which US cities are most popular for immigration. Providing data on demographics on the arrivals, such as gender, visa types, median ages, etc. As well as providing data on the climates of different cities to study any corelation between temperature and rate of immigrations. And airport data to identify trends in which airlines are most used and departure destinations.Spark was used for the ETL pipeline and data stored in parquet for analysis. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from data_quality_check import data_quality_check\n",
    "from etl import create_valid_ports, clean_table, clean_i94, add_port\n",
    "from create_model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**I94 Immigration Data:** This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read immigration file\n",
    "immigration_fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "i94_df = spark.read.format('com.github.saurfang.sas.spark').load(immigration_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-6c18f3a9": {
       "style": "primary"
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display immigration file data\n",
    "i94_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**World Temperature Data:** This dataset came from Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read temperature file\n",
    "temperature_fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = spark.read.format('csv').option('delimiter',',').option('header','true').load(temperature_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**U.S. City Demographic Data:** This data comes from OpenSoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read demographics file\n",
    "demographics_fname = 'us-cities-demographics.csv'\n",
    "demographics_df = spark.read.format('csv').option('delimiter',';').option('header','true').load(demographics_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Airport Code Table:** This is a simple table of airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read airport code file\n",
    "airport_code_fname = 'airport-codes_csv.csv'\n",
    "airport_code_df = spark.read.format('csv').option('delimiter',',').option('header','true').load(airport_code_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_code_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.cache()\n",
    "i94_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.cache()\n",
    "temperature_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.cache()\n",
    "demographics_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_df.cache()\n",
    "airport_code_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in i94 before clenaing: 3096313\n",
      "number of rows in i94 after clenaing: 2995590\n"
     ]
    }
   ],
   "source": [
    "# Create a list of valid ports and drop empty columns \n",
    "dropped_i94_df = clean_i94(i94_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cleaning 9.5367431640625e-07\n",
      "number of rows in table before removing empty rows: 2995590\n",
      "number of rows in table after removing empty rows: 2306750\n",
      "finish cleaning 6.036678075790405\n",
      "show\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|entdepa|entdepd|matflag|biryear| dtaddto|gender|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|      G|      O|      M| 1958.0|04062016|     M|     LH|9.247876383E10|00422|      B1|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|      G|      O|      M| 1960.0|04062016|     F|     LH|9.247890033E10|00422|      B1|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|      G|      O|      M| 1954.0|09302016|     M|     AZ|9.250378143E10|00614|      B2|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|      G|      O|      M| 1967.0|09302016|     M|     OS|9.247020943E10|00089|      B2|\n",
      "| 31.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NY|20611.0|  43.0|    2.0|  1.0|20160401|      G|      O|      M| 1973.0|09302016|     M|     OS|9.247128923E10|00089|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.3587057590484619\n"
     ]
    }
   ],
   "source": [
    "# Drop empty rows in i94 dataframe\n",
    "cleaned_i94_df = clean_table(dropped_i94_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add port\n",
      "complete adding 0.06515860557556152\n",
      "+----------+-------------------+-----------------------------+-----+-------+--------+---------+-------+\n",
      "|        dt| AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|i94port|\n",
      "+----------+-------------------+-----------------------------+-----+-------+--------+---------+-------+\n",
      "|1743-11-01|              6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-04-01| 5.7879999999999985|           3.6239999999999997|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-05-01|             10.644|           1.2830000000000001|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-06-01| 14.050999999999998|                        1.347|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-07-01|             16.082|                        1.396|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-09-01| 12.780999999999999|                        1.454|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-10-01|               7.95|                         1.63|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-11-01|  4.638999999999999|           1.3019999999999998|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1744-12-01|0.12199999999999987|                        1.756|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1745-01-01|-1.3330000000000002|                        1.642|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1745-02-01|             -2.732|                        1.358|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1745-03-01|              0.129|                        1.088|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1745-04-01|              4.042|                        1.138|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-01-01|              1.699|                        1.013|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-02-01| 3.9610000000000003|           2.3609999999999998|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-03-01|              5.182|                         3.48|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-04-01|              7.197|                        0.732|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-05-01|             10.634|                        1.351|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-06-01|             14.913|                        1.181|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "|1750-07-01|             17.831|                         1.22|Århus|Denmark|  57.05N|   10.33E|   null|\n",
      "+----------+-------------------+-----------------------------+-----+-------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "start filter 144.82457852363586\n",
      "finish filter 0.15976214408874512\n",
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|    City|       Country|Latitude|Longitude|i94port|\n",
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "|1743-11-01|             8.758|                        1.886|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-04-01|6.0699999999999985|           2.9339999999999997|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-05-01|             7.751|                        1.494|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-06-01|             10.62|                        1.574|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-07-01|             12.35|                        1.591|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-09-01|            11.224|           1.6059999999999999|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-10-01|             8.945|           1.7309999999999999|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-11-01|             7.836|                        1.585|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1744-12-01|             5.263|                        1.871|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1745-01-01|             4.136|                        1.825|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1745-02-01|             2.436|           1.6769999999999998|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1745-03-01|              3.24|                        1.456|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1745-04-01|             4.819|                        1.429|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-01-01|             5.441|                        1.463|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-02-01|              7.31|                        2.474|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-03-01|             7.335|           3.0239999999999996|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-04-01|             6.604|                        1.308|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-05-01| 8.328000000000001|           1.5090000000000001|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-06-01|            10.803|                        1.393|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|1750-07-01|            14.367|                          1.4|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop empty rows in temperature dataframe\n",
    "temperature_df = temperature_df.filter(temperature_df.AverageTemperature != 'NaN')\n",
    "temperature_df = temperature_df.filter(temperature_df.AverageTemperature != 'null')\n",
    "temperature_df.cache()\n",
    "new_temperature_df = add_port(temperature_df)\n",
    "new_temperature_df.cache()\n",
    "new_temperature_df.count()\n",
    "cleaned_temperature_df = clean_table(new_temperature_df)\n",
    "cleaned_temperature_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop empty rows in demographics dataframe\n",
    "new_demographics_df = add_port(demographics_df)\n",
    "cleaned_demographics_df = clean_table(new_demographics_df)\n",
    "fixed_cleaned_demographics_df = cleaned_demographics_df.withColumnRenamed('Median Age','median_age') \\\n",
    "                                                        .withColumnRenamed('Male Population', 'male_population') \\\n",
    "                                                        .withColumnRenamed('Female Population', 'female_population') \\\n",
    "                                                        .withColumnRenamed('Total Population', 'total_population') \\\n",
    "                                                        .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "                                                        .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "                                                        .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "                                                        .withColumnRenamed('State Code', 'state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop empty rows in airport code dataframe\n",
    "cleaned_airport_code_df = clean_table(airport_code_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "| table | columns | description | type |\n",
    "|---|---|---|---|\n",
    "| Immigrations | cicid; i94yr; i94mon; i94cit; i94res; i94port; arrdate; i94mode; i94addr; depdate; i94bir; i94visa; count; dtadfile; entdepa; entdepd; matflag; biryear; dtaddto; gender; airline; admnum; fltno; visatype;  | Contains i94 immigration data | Fact Table |\n",
    "| Temperature | dt; AverageTemperature; AverageTemperatureUncertainty;  City; Country; Latitude; Longitude;  | Contains temperature data | Dimension Table |\n",
    "| Demographics | City; State; Median Age; Male Population; Female Population; Total Population; Number of Veterans; Foreign-born; Average Household Size; State Code; Race; Count;  | Contains airport data | Dimension Table |\n",
    "| Airport | ident; type; name; elevation_ft; continent; iso_country; iso_region;  municipality; gps_code; iata_code; local_code; coordinates; | Contains demographicsdata | Dimension Table |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Clean data.\n",
    "2. Create fact table from immigrations file.\n",
    "3. Create dimensions tables from temperature, airport code, and emographics files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%rm -rf ./output/\n",
    "create_model(cleaned_i94_df, cleaned_temperature_df, fixed_cleaned_demographics_df, cleaned_airport_code_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_quality_check(cleaned_i94_df)\n",
    "data_quality_check(cleaned_temperature_df)\n",
    "data_quality_check(fixed_cleaned_demographics_df)\n",
    "data_quality_check(cleaned_airport_code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read parquet files\n",
    "parI94 = spark.read.parquet(\"./output/immigration_table.parquet\")\n",
    "parTemp= spark.read.parquet(\"./output/temperature_table.parquet\")\n",
    "parDem = spark.read.parquet(\"./output/demographics_table.parquet\")\n",
    "parAir = spark.read.parquet(\"./output/airport_code_table.parquet\")\n",
    "\n",
    "parI94.createOrReplaceTempView(\"immigration\")\n",
    "parTemp.createOrReplaceTempView(\"temperature\")\n",
    "parDem.createOrReplaceTempView(\"demographics\")\n",
    "parAir.createOrReplaceTempView(\"airport\")\n",
    "\n",
    "parI94.show()\n",
    "parTemp.show()\n",
    "parDem.show()\n",
    "parAir.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Query parquet files to test successful ETL processing\n",
    "# Get the average household size of all immagrant to Los Angeles that are older than ~30 years old\n",
    "spark.sql(\"SELECT AVG(average_household_size) FROM immigration JOIN demographics on (immigration.i94port = demographics.i94port) WHERE demographics.city='Los Angeles' AND immigration.i94bir < 1980.0\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Dimension Tables:\n",
    "\n",
    "**Temperature:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| dt | Datetime stamp |\n",
    "| AverageTemperature | Avg Temp of city |\n",
    "| AverageTemperatureUncertainty | Uncertainty of Avg Temp of city|\n",
    "| City | City name |\n",
    "| Country | Country name |\n",
    "| Latitude | Latitude coordinates |\n",
    "| Longitude | Longitude coordinates|\n",
    "\n",
    "**Demographics:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| City | City name |\n",
    "| State | State name|\n",
    "| Median Age | Average age of residents |\n",
    "| Male Population | Number of male residents |\n",
    "| Female Population | Number of female residents |\n",
    "| Total Population | Number of total residents |\n",
    "| Number of Veterans | Number of residents that are veterans |\n",
    "| Foreign-born | Number of residents not born in country |\n",
    "| Average Household Size | Average size of residents in single house |\n",
    "| State Code | Two letter state code |\n",
    "| Race | Most promemnant race in country |\n",
    "| Count | Count of largest race demographic |\n",
    "\n",
    "\n",
    "**Airport Code:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| ident | Airport identity number |\n",
    "| type | Type of airport by size |\n",
    "| name | Airport name |\n",
    "| elevation_ft | Elevation of airport in feet |\n",
    "| continent | Continent of the airport |\n",
    "| iso_country | Country of airport |\n",
    "| iso_region | Region of airport within country |\n",
    "| municipality | Municipality of airport |\n",
    "| gps_code | GPS code |\n",
    "| iata_code | IATA code |\n",
    "| local_code | Local identity code |\n",
    "| coordinates | Latitude and Longitude of airport |\n",
    "\n",
    "\n",
    "### Fact Table:\n",
    "\n",
    "**Immigration:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| cicid | Record ID |\n",
    "| i94yr | 4 digit year|\n",
    "| i94mon | Month |\n",
    "| i94cit | Country of citizenship |\n",
    "| i94res | Country of residence |\n",
    "| i94port | Port of entry |\n",
    "| arrdate | Arrivate date |\n",
    "| i94mode | Mode of transportation |\n",
    "| i94addr | State of arrival in USA |\n",
    "| depdate | Departure date |\n",
    "| i94bir | Birth year of respondant |\n",
    "| i94visa | Visa type |\n",
    "| count | Summary statistics |\n",
    "| dtadfile | Date added to i94 files |\n",
    "| entdepa | Arrival flag |\n",
    "| entdepd | Departure flag |\n",
    "| matflag | Match flag |\n",
    "| biryear | Birth year |\n",
    "| dtaddto | Date admitted to USA |\n",
    "| gender | Gender of respondant |\n",
    "| airline | Airline of entry |\n",
    "| admnum | Admission number |\n",
    "| fltno | Flight number |\n",
    "| visatype | Type of visa held by repondant |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Rationale:\n",
    "Using Spark allows for the ability to handle multiple file formats that contians many rows of data. And allows integration with Redshift or increasing nodes should requirments change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Update Schedule \n",
    "This depends on the update cycle of the data itself, in the ase of temperature data, since it is updated monthly, we can adopt a monthly update cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Scenarios:\n",
    "- The data was increased by 100x.\n",
    "    * Using Spark, we can scale up by increasing the number of worker nodes working on the data.\n",
    "- The data populates a ddashboardashboard that must be updated on a daily basis by 7am every day.\n",
    "    * Integration with Apache Airflow can be performed to allow a scheduled DAG to query the data everyday at 7am.\n",
    "- The database needed to be accessed by 100+ people.\n",
    "    * Data can be migrated to Redshift to allow auto-scaling capabilities to handle the load of increased access by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
